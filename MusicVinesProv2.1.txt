#!/usr/bin/env python3
# MusicVines Pro V2.1: Grok Imagine-powered short music video app
# Updated December 31, 2025
# - Fully legal: User-provided audio only, no pirated content
# - Core generation: Placeholder for future Grok Imagine text-to-video API
# - Manual fallback: User generates in Grok app and uploads base video
# - Enhanced audio handling: Fade in/out, volume normalization, loop/trim to match
# - Improved Grok 4 analysis with better keyframe selection
# - Richer error handling and task progress feedback
# - Font fallbacks for cross-platform compatibility
# - Added prompt engineering tips in API response

import os
import uuid
import json
import logging
import mimetypes
import base64
import io
import requests
from pathlib import Path
from datetime import datetime
from typing import Optional, List

from flask import Flask, request, jsonify, url_for, send_from_directory
from flask_limiter import Limiter
from flask_limiter.util import get_remote_address
from flask_caching import Cache
from flask_cors import CORS
from flask_wtf.csrf import CSRFProtect
from werkzeug.utils import secure_filename
from dotenv import load_dotenv
from celery import Celery
from moviepy.editor import AudioFileClip, VideoFileClip, ImageClip, CompositeVideoClip, TextClip, ColorClip, afx
from moviepy.video.tools.drawing import waveform
from moviepy.video.io.bindings import mplfig_to_npimage
from moviepy.audio.fx.all import volumex
from PIL import Image
import numpy as np
import matplotlib.pyplot as plt

load_dotenv()

app = Flask(__name__, static_folder='uploads')
CORS(app, resources={r"/*": {"origins": os.getenv('ALLOWED_ORIGINS', '*')}})
csrf = CSRFProtect(app)

# === Configuration ===
UPLOAD_FOLDER = Path(os.getenv('UPLOAD_FOLDER', 'uploads')).resolve()
app.config.update(
    SECRET_KEY=os.getenv('FLASK_SECRET_KEY', str(uuid.uuid4())),
    UPLOAD_FOLDER=str(UPLOAD_FOLDER),
    MAX_CONTENT_LENGTH=500 * 1024 * 1024,
    CELERY_BROKER_URL=os.getenv('CELERY_BROKER_URL', 'redis://localhost:6379/0'),
    CELERY_RESULT_BACKEND=os.getenv('CELERY_RESULT_BACKEND', 'redis://localhost:6379/0')
)

XAI_API_KEY = os.getenv('XAI_API_KEY')
XAI_CHAT_URL = "https://api.x.ai/v1/chat/completions"
XAI_IMAGE_URL = "https://api.x.ai/v1/images/generations"  # Existing image endpoint
# Future hypothetical video endpoint (not yet available as of Dec 31, 2025)
XAI_VIDEO_URL = os.getenv('XAI_VIDEO_URL', 'https://api.x.ai/v1/video/generations')  # Placeholder

celery = Celery(app.name, broker=app.config['CELERY_BROKER_URL'])
celery.conf.update(app.config)

cache = Cache(app, config={'CACHE_TYPE': 'RedisCache', 'CACHE_REDIS_URL': os.getenv('REDIS_URL', 'redis://localhost:6379/0')})

def get_user_key():
    return f"{request.form.get('user_id') or request.args.get('user_id') or 'anonymous'}:{get_remote_address()}"

limiter = Limiter(app=app, key_func=get_user_key, default_limits=["100 per day", "30 per hour"])

logging.basicConfig(level=logging.INFO, format='%(asctime)s [%(levelname)s] %(message)s')
logger = logging.getLogger(__name__)

# === Font Fallback Helper ===
def get_available_font(preferred: str, fallback: str = 'Arial'):
    available = TextClip.list('font')
    return preferred if preferred in available else fallback

TITLE_FONT = get_available_font('Amiri-Bold', 'Arial-Bold')
CAPTION_FONT = get_available_font('Amiri', 'Arial')

# === Grok Image Fallback ===
def generate_fallback_background(prompt: str) -> Optional[Path]:
    if not XAI_API_KEY:
        return None

    payload = {
        "model": "grok-2-image",
        "prompt": prompt,
        "n": 1,
        "response_format": "url"
    }
    headers = {"Authorization": f"Bearer {XAI_API_KEY}"}

    try:
        resp = requests.post(XAI_IMAGE_URL, json=payload, headers=headers, timeout=90)
        resp.raise_for_status()
        img_url = resp.json()["data"][0]["url"]
        img_resp = requests.get(img_url, timeout=30)
        img_resp.raise_for_status()
        img = Image.open(io.BytesIO(img_resp.content))

        out_path = UPLOAD_FOLDER / f"fallback_bg_{uuid.uuid4()}.jpg"
        img.save(out_path)
        return out_path
    except Exception as e:
        logger.error(f"Fallback image generation failed: {e}")
        return None

# === Improved Keyframe Extraction (more diverse spacing) ===
def extract_keyframes(video_path: Path, n: int = 6) -> List[Path]:
    keyframes = []
    try:
        clip = VideoFileClip(str(video_path))
        duration = clip.duration
        clip.reader.close()
        if clip.audio:
            clip.audio.reader.close_proc()

        # Exponential spacing for more dynamic coverage (early frames denser)
        times = np.logspace(0.1, 1, n) / 10 * duration
        for i, t in enumerate(times):
            frame = clip.get_frame(t)
            img = Image.fromarray(frame)
            temp_path = UPLOAD_FOLDER / f"keyframe_{uuid.uuid4()}_{i}.jpg"
            img.save(temp_path)
            keyframes.append(temp_path)
    except Exception as e:
        logger.error(f"Keyframe extraction failed: {e}")
    return keyframes

# === Grok 4 Analysis ===
class Grok4API:
    @staticmethod
    def analyze_clip(keyframe_paths: List[Path], caption: str) -> str:
        if not XAI_API_KEY or not keyframe_paths:
            return "Vibrant AI music video magic! ✨ #Grok #AIMusic #MusicVideo"

        images_base64 = []
        for path in keyframe_paths:
            with open(path, "rb") as f:
                images_base64.append(base64.b64encode(f.read()).decode('utf-8'))

        messages = [
            {"role": "system", "content": "You are a viral short-video expert for platforms like TikTok/Reels. Suggest an optimized caption, 8-12 targeted hashtags, and 3 reasons why this clip could go viral."},
            {"role": "user", "content": [
                {"type": "text", "text": f"Analyze these keyframes from an AI-generated music video. User caption: '{caption}'. Provide optimized caption, hashtags, and viral tips."},
                *[ {"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{b64}"}} for b64 in images_base64 ]
            ]}
        ]

        payload = {
            "model": "grok-4",
            "messages": messages,
            "temperature": 0.8,
            "max_tokens": 512
        }
        headers = {"Authorization": f"Bearer {XAI_API_KEY}"}

        try:
            resp = requests.post(XAI_CHAT_URL, json=payload, headers=headers, timeout=60)
            resp.raise_for_status()
            return resp.json()["choices"][0]["message"]["content"]
        except Exception as e:
            logger.error(f"Grok analysis failed: {e}")
            return "Epic AI vibes! #GrokImagine #MusicVideo"

# === Enhanced Audio Processing ===
def process_user_audio(user_audio_path: Path, target_duration: float) -> AudioFileClip:
    audio = AudioFileClip(str(user_audio_path))
    
    # Normalize volume
    audio = volumex(audio, 1.0)  # moviepy has no built-in normalizer, but we can approximate
    
    # Trim or loop to match video duration
    if audio.duration > target_duration:
        audio = audio.subclip(0, target_duration)
    elif audio.duration < target_duration:
        loops = int(np.ceil(target_duration / audio.duration))
        audio = CompositeAudioClip([audio] * loops).subclip(0, target_duration)
    
    # Fade in/out
    audio = afx.audio_fadein(audio, 1.0).audio_fadeout(1.0)
    
    return audio

# === Video Enhancement ===
def enhance_video(base_video_path: Path, output_path: Path, title: str, caption: str, duration: float):
    video = VideoFileClip(str(base_video_path))

    # Parallax zoom
    zoomed = video.resize(lambda t: 1 + 0.03 * t / duration).set_position("center")

    # Waveform overlay
    audio = video.audio
    fig, ax = plt.subplots(figsize=(10.8, 3))
    waveform(audio, width=1080, height=300, color=(255, 255, 255, 180), fig=fig, ax=ax)
    waveform_img = mplfig_to_npimage(fig)
    plt.close(fig)
    waveform_clip = ImageClip(waveform_img).set_duration(duration).set_pos(("center", "bottom")).margin(bottom=100, opacity=0)

    # Text overlays with fallbacks
    title_txt = TextClip(title, fontsize=80, color='white', font=TITLE_FONT, stroke_color='black', stroke_width=4)
    caption_txt = TextClip(caption, fontsize=50, color='white', font=CAPTION_FONT, stroke_color='black', stroke_width=2)

    text_composite = CompositeVideoClip([
        title_txt.set_pos(("center", 200)).set_duration(duration),
        caption_txt.set_pos(("center", 1600)).set_duration(duration).margin(bottom=400, opacity=0)
    ])

    final = CompositeVideoClip([
        ColorClip(size=(1080, 1920), color=(0,0,0)).set_duration(duration),
        zoomed,
        waveform_clip,
        text_composite
    ], size=(1080, 1920)).set_audio(audio)

    final.write_videofile(str(output_path), fps=30, codec="libx264", audio_codec="aac", threads=8, preset="medium", logger=None)

    video.close()
    final.close()

# === Future Grok Video Generation Hook ===
def generate_grok_video(prompt: str, duration: float = 15.0) -> Optional[Path]:
    """
    Placeholder for future xAI text-to-video API.
    As of Dec 31, 2025, Grok Imagine video is available in apps/web but NOT via public API.
    When released, implement here (hypothetical example below).
    """
    if not XAI_API_KEY:
        return None

    # Hypothetical payload – replace with real when available
    payload = {
        "model": "grok-imagine-video",
        "prompt": prompt + " Vertical 9:16 short music video format, cinematic, high energy.",
        "duration": duration,
        "aspect_ratio": "9:16",
        "with_audio": False  # We'll overlay user audio
    }
    headers = {"Authorization": f"Bearer {XAI_API_KEY}"}

    try:
        resp = requests.post(XAI_VIDEO_URL, json=payload, headers=headers, timeout=180)
        resp.raise_for_status()
        video_url = resp.json()["data"][0]["url"]
        video_resp = requests.get(video_url, timeout=60)
        video_resp.raise_for_status()

        out_path = UPLOAD_FOLDER / f"grok_video_{uuid.uuid4()}.mp4"
        out_path.write_bytes(video_resp.content)
        return out_path
    except Exception as e:
        logger.warning(f"Grok video API not available or failed: {e}")
        return None

# === Celery Task with Progress ===
@celery.task(bind=True, max_retries=3)
def process_grok_clip_task(self, prompt: str, caption: str, user_id: str, audio_file: Optional[str] = None, base_video_file: Optional[str] = None):
    task_id = self.request.id
    self.update_state(state='PROGRESS', meta={'progress': 10, 'status': 'Starting generation'})

    base_video_path = None

    # Step 1: Try future API (will fail until released)
    base_video_path = generate_grok_video(prompt)

    # Step 2: Fallback to user-uploaded base video
    if not base_video_path and base_video_file:
        base_video_path = UPLOAD_FOLDER / base_video_file
        if not base_video_path.exists():
            raise ValueError("Uploaded base video not found")

    if not base_video_path:
        raise ValueError("No base video generated or provided. Use Grok app to generate with prompt and upload as base video.")

    self.update_state(state='PROGRESS', meta={'progress': 30, 'status': 'Loading video'})

    try:
        clip = VideoFileClip(str(base_video_path))
        duration = clip.duration
        title = prompt[:50] + "..." if len(prompt) > 50 else prompt
        clip.close()
    except Exception as e:
        raise ValueError(f"Invalid base video: {str(e)}")

    filename = secure_filename(f"{uuid.uuid4()}.mp4")
    output_path = UPLOAD_FOLDER / filename

    self.update_state(state='PROGRESS', meta={'progress': 50, 'status': 'Processing audio'})

    # Optional user audio overlay with enhancements
    if audio_file:
        user_audio_path = UPLOAD_FOLDER / audio_file
        if user_audio_path.exists():
            user_audio = process_user_audio(user_audio_path, duration)
            clip = VideoFileClip(str(base_video_path)).set_audio(user_audio)
            clip.duration = duration  # Ensure duration matches
        else:
            raise ValueError("Uploaded audio file not found")
    else:
        clip = VideoFileClip(str(base_video_path))

    self.update_state(state='PROGRESS', meta={'progress': 70, 'status': 'Enhancing video'})

    enhance_video(base_video_path, output_path, title, caption, duration)
    clip.close()

    self.update_state(state='PROGRESS', meta={'progress': 85, 'status': 'Analyzing with Grok 4'})

    keyframes = extract_keyframes(output_path, n=6)
    analysis = Grok4API.analyze_clip(keyframes, caption)

    # Cleanup
    for kf in keyframes:
        try: kf.unlink(missing_ok=True)
        except: pass

    video_url = url_for('static', filename=filename, _external=True)

    return {
        "video_url": video_url,
        "analysis": analysis,
        "caption": caption,
        "prompt": prompt,
        "user_id": user_id,
        "progress": 100,
        "status": "completed"
    }

# === Routes ===
@app.route('/clip_grok', methods=['POST'])
@limiter.limit("10 per minute")
def clip_grok():
    data = request.json or {}
    prompt = data.get('prompt', 'A vibrant cinematic abstract music visualization with pulsing lights and particles')
    caption = data.get('caption', 'AI-generated music magic ✨')
    user_id = data.get('user_id', 'anonymous')
    audio_filename = data.get('audio_filename')
    base_video_filename = data.get('base_video_filename')  # Optional uploaded base

    task = process_grok_clip_task.delay(prompt, caption, user_id, audio_filename, base_video_filename)

    prompt_tips = (
        "Pro tip for best Grok Imagine results: Describe mood, tempo, camera moves, lighting. "
        "E.g., 'Cyberpunk neon city flythrough with pulsing bass, dramatic parallax zoom, vertical 9:16'"
    )

    return jsonify({
        "task_id": task.id,
        "note": "As of Dec 31, 2025, text-to-video API not public. Generate in Grok app/web, download, upload via /upload_base.",
        "prompt_tips": prompt_tips
    })

@app.route('/upload_audio', methods=['POST'])
def upload_audio():
    if 'audio' not in request.files:
        return jsonify({"error": "No audio file"}), 400
    file = request.files['audio']
    if file.filename == '':
        return jsonify({"error": "No selected file"}), 400
    filename = secure_filename(f"user_audio_{uuid.uuid4()}_{file.filename}")
    file.save(UPLOAD_FOLDER / filename)
    return jsonify({"audio_filename": filename})

@app.route('/upload_base', methods=['POST'])
def upload_base():
    if 'base_video' not in request.files:
        return jsonify({"error": "No base video file"}), 400
    file = request.files['base_video']
    if file.filename == '':
        return jsonify({"error": "No selected file"}), 400
    filename = secure_filename(f"base_{uuid.uuid4()}_{file.filename}")
    file.save(UPLOAD_FOLDER / filename)
    return jsonify({"base_video_filename": filename})

@app.route('/task_status/<task_id>')
def task_status(task_id):
    task = process_grok_clip_task.AsyncResult(task_id)
    if task.state == 'PENDING':
        response = {'state': task.state, 'status': 'Pending...'}
    elif task.state in ['PROGRESS', 'SUCCESS']:
        response = {'state': task.state, 'result': task.info if task.info else {}}
    else:  # FAILURE or others
        response = {'state': task.state, 'status': str(task.info) if task.info else 'Failed'}
    return jsonify(response)

@app.route('/')
def index():
    return "MusicVines Pro V2.1 (Grok Imagine Edition) API Running – Fully Legal & AI-Powered! (Dec 31, 2025)"

if __name__ == '__main__':
    os.makedirs(UPLOAD_FOLDER, exist_ok=True)
    app.run(debug=False, host='0.0.0.0', port=5000)