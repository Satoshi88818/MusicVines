#!/usr/bin/env python3
# MusicVines Pro V2.2: Grok Imagine-powered short music video app
# Updated: Current date (improvements applied)
# - Fixed waveform overlay: Implemented custom reactive waveform using matplotlib
# - Proper audio normalization: Custom peak normalization (safe for silent clips)
# - Better audio looping: Use built-in .loop() method
# - Improved keyframe spacing: Switched to more balanced logarithmic-biased spacing
# - Enhanced cleanup and resource management
# - Minor optimizations and robustness improvements
# - Fully legal: User-provided audio only

import os
import uuid
import json
import logging
import mimetypes
import base64
import io
import requests
from pathlib import Path
from datetime import datetime
from typing import Optional, List

from flask import Flask, request, jsonify, url_for, send_from_directory
from flask_limiter import Limiter
from flask_limiter.util import get_remote_address
from flask_caching import Cache
from flask_cors import CORS
from flask_wtf.csrf import CSRFProtect
from werkzeug.utils import secure_filename
from dotenv import load_dotenv
from celery import Celery
from moviepy.editor import AudioFileClip, VideoFileClip, ImageClip, CompositeVideoClip, TextClip, ColorClip
from moviepy.audio.fx.all import audio_fadein, audio_fadeout
from moviepy.video.fx.all import resize
from moviepy.audio.AudioClip import CompositeAudioClip
from PIL import Image
import numpy as np
import matplotlib.pyplot as plt

load_dotenv()

app = Flask(__name__, static_folder='uploads')
CORS(app, resources={r"/*": {"origins": os.getenv('ALLOWED_ORIGINS', '*')}})
csrf = CSRFProtect(app)

# === Configuration ===
UPLOAD_FOLDER = Path(os.getenv('UPLOAD_FOLDER', 'uploads')).resolve()
app.config.update(
    SECRET_KEY=os.getenv('FLASK_SECRET_KEY', str(uuid.uuid4())),
    UPLOAD_FOLDER=str(UPLOAD_FOLDER),
    MAX_CONTENT_LENGTH=500 * 1024 * 1024,
    CELERY_BROKER_URL=os.getenv('CELERY_BROKER_URL', 'redis://localhost:6379/0'),
    CELERY_RESULT_BACKEND=os.getenv('CELERY_RESULT_BACKEND', 'redis://localhost:6379/0')
)

XAI_API_KEY = os.getenv('XAI_API_KEY')
XAI_CHAT_URL = "https://api.x.ai/v1/chat/completions"
XAI_IMAGE_URL = "https://api.x.ai/v1/images/generations"
XAI_VIDEO_URL = os.getenv('XAI_VIDEO_URL', 'https://api.x.ai/v1/video/generations')  # Placeholder

celery = Celery(app.name, broker=app.config['CELERY_BROKER_URL'])
celery.conf.update(app.config)

cache = Cache(app, config={'CACHE_TYPE': 'RedisCache', 'CACHE_REDIS_URL': os.getenv('REDIS_URL', 'redis://localhost:6379/0')})

def get_user_key():
    return f"{request.form.get('user_id') or request.args.get('user_id') or 'anonymous'}:{get_remote_address()}"

limiter = Limiter(app=app, key_func=get_user_key, default_limits=["100 per day", "30 per hour"])

logging.basicConfig(level=logging.INFO, format='%(asctime)s [%(levelname)s] %(message)s')
logger = logging.getLogger(__name__)

# === Font Fallback Helper ===
def get_available_font(preferred: str, fallback: str = 'Arial'):
    available = TextClip.list('font')
    return preferred if preferred in available else fallback

TITLE_FONT = get_available_font('Amiri-Bold', 'Arial-Bold')
CAPTION_FONT = get_available_font('Amiri', 'Arial')

# === Grok Image Fallback ===
def generate_fallback_background(prompt: str) -> Optional[Path]:
    if not XAI_API_KEY:
        return None

    payload = {
        "model": "grok-2-image",
        "prompt": prompt,
        "n": 1,
        "response_format": "url"
    }
    headers = {"Authorization": f"Bearer {XAI_API_KEY}"}

    try:
        resp = requests.post(XAI_IMAGE_URL, json=payload, headers=headers, timeout=90)
        resp.raise_for_status()
        img_url = resp.json()["data"][0]["url"]
        img_resp = requests.get(img_url, timeout=30)
        img_resp.raise_for_status()
        img = Image.open(io.BytesIO(img_resp.content))

        out_path = UPLOAD_FOLDER / f"fallback_bg_{uuid.uuid4()}.jpg"
        img.save(out_path)
        return out_path
    except Exception as e:
        logger.error(f"Fallback image generation failed: {e}")
        return None

# === Improved Keyframe Extraction ===
def extract_keyframes(video_path: Path, n: int = 6) -> List[Path]:
    keyframes = []
    try:
        clip = VideoFileClip(str(video_path))
        duration = clip.duration
        clip.close()

        # Balanced spacing: denser early, spreads out later
        exponents = np.linspace(0.3, 1.0, n)
        times = (np.power(2, exponents) - 1) / (2 - 1) * duration

        for i, t in enumerate(times):
            frame = clip.get_frame(t)
            img = Image.fromarray(frame)
            temp_path = UPLOAD_FOLDER / f"keyframe_{uuid.uuid4()}_{i}.jpg"
            img.save(temp_path)
            keyframes.append(temp_path)
    except Exception as e:
        logger.error(f"Keyframe extraction failed: {e}")
    finally:
        if 'clip' in locals():
            clip.close()
    return keyframes

# === Grok 4 Analysis ===
class Grok4API:
    @staticmethod
    def analyze_clip(keyframe_paths: List[Path], caption: str) -> str:
        if not XAI_API_KEY or not keyframe_paths:
            return "Vibrant AI music video magic! ✨ #Grok #AIMusic #MusicVideo"

        images_base64 = []
        for path in keyframe_paths:
            with open(path, "rb") as f:
                images_base64.append(base64.b64encode(f.read()).decode('utf-8'))

        messages = [
            {"role": "system", "content": "You are a viral short-video expert for platforms like TikTok/Reels. Suggest an optimized caption, 8-12 targeted hashtags, and 3 reasons why this clip could go viral."},
            {"role": "user", "content": [
                {"type": "text", "text": f"Analyze these keyframes from an AI-generated music video. User caption: '{caption}'. Provide optimized caption, hashtags, and viral tips."},
                *[ {"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{b64}"}} for b64 in images_base64 ]
            ]}
        ]

        payload = {
            "model": "grok-4",
            "messages": messages,
            "temperature": 0.8,
            "max_tokens": 512
        }
        headers = {"Authorization": f"Bearer {XAI_API_KEY}"}

        try:
            resp = requests.post(XAI_CHAT_URL, json=payload, headers=headers, timeout=60)
            resp.raise_for_status()
            return resp.json()["choices"][0]["message"]["content"]
        except Exception as e:
            logger.error(f"Grok analysis failed: {e}")
            return "Epic AI vibes! #GrokImagine #MusicVideo"

# === Proper Audio Normalization ===
def normalize_audio(audio: AudioFileClip) -> AudioFileClip:
    try:
        max_volume = audio.max_volume()
        if max_volume == 0:
            return audio  # Silent clip – avoid division by zero
        factor = 1.0 / max_volume
        return audio.volumex(factor)
    except:
        return audio  # Fallback if max_volume fails

# === Enhanced Audio Processing ===
def process_user_audio(user_audio_path: Path, target_duration: float) -> AudioFileClip:
    audio = AudioFileClip(str(user_audio_path))
    
    # Proper peak normalization
    audio = normalize_audio(audio)
    
    # Loop or trim to match video duration
    if audio.duration < target_duration:
        audio = audio.loop(duration=target_duration)
    elif audio.duration > target_duration:
        audio = audio.subclip(0, target_duration)
    
    # Fade in/out
    audio = audio_fadein(audio, 1.0)
    audio = audio_fadeout(audio, 1.0)
    
    return audio

# === Custom Reactive Waveform Overlay ===
def make_waveform_clip(audio: AudioFileClip, duration: float, size=(1080, 300)):
    fig, ax = plt.subplots(figsize=(size[0]/100, size[1]/100), dpi=100)
    ax.set_facecolor((0, 0, 0, 0))  # Transparent background
    ax.axis('off')
    
    def make_frame(t):
        ax.clear()
        ax.set_xlim(0, duration)
        ax.set_ylim(-1, 1)
        
        # Downsample audio around current time for reactivity
        window = 0.2  # seconds around current time
        start = max(0, t - window)
        end = min(duration, t + window)
        samples = audio.to_soundarray(ttl=duration, fps=44100)[int(start*44100):int(end*44100)]
        if len(samples.shape) > 1:
            samples = np.mean(samples, axis=1)
        
        times = np.linspace(t - window, t + window, len(samples))
        ax.plot(times, samples, color='white', lw=1.5, alpha=0.8)
        ax.fill_between(times, samples, color='cyan', alpha=0.4)
        
        return mplfig_to_npimage(fig)
    
    plt.close('all')  # Prevent memory leaks
    return VideoFileClip(make_frame, duration=duration).set_position(("center", "bottom")).margin(bottom=150, opacity=0)

# === Video Enhancement ===
def enhance_video(base_video_path: Path, output_path: Path, title: str, caption: str, audio_clip: AudioFileClip):
    video = VideoFileClip(str(base_video_path))
    duration = video.duration

    # Parallax zoom effect
    zoomed = video.fx(resize, lambda t: 1 + 0.03 * t / duration).set_position("center")

    # Reactive waveform
    waveform_clip = make_waveform_clip(audio_clip, duration)

    # Text overlays
    title_txt = TextClip(title, fontsize=80, color='white', font=TITLE_FONT,
                         stroke_color='black', stroke_width=4).set_pos(("center", 200)).set_duration(duration)
    
    caption_txt = TextClip(caption, fontsize=50, color='white', font=CAPTION_FONT,
                           stroke_color='black', stroke_width=2).set_pos(("center", "bottom")).set_duration(duration).margin(bottom=500, opacity=0)

    # Final composition
    final = CompositeVideoClip([
        ColorClip(size=(1080, 1920), color=(0,0,0)).set_duration(duration),  # Background
        zoomed,
        waveform_clip,
        title_txt,
        caption_txt
    ], size=(1080, 1920)).set_audio(audio_clip)

    final.write_videofile(str(output_path), fps=30, codec="libx264", audio_codec="aac",
                          threads=8, preset="medium", logger=None)

    video.close()
    final.close()

# === Future Grok Video Generation Hook ===
def generate_grok_video(prompt: str, duration: float = 15.0) -> Optional[Path]:
    if not XAI_API_KEY:
        return None

    payload = {
        "model": "grok-imagine-video",
        "prompt": prompt + " Vertical 9:16 short music video format, cinematic, high energy.",
        "duration": duration,
        "aspect_ratio": "9:16",
        "with_audio": False
    }
    headers = {"Authorization": f"Bearer {XAI_API_KEY}"}

    try:
        resp = requests.post(XAI_VIDEO_URL, json=payload, headers=headers, timeout=180)
        resp.raise_for_status()
        video_url = resp.json()["data"][0]["url"]
        video_resp = requests.get(video_url, timeout=60)
        video_resp.raise_for_status()

        out_path = UPLOAD_FOLDER / f"grok_video_{uuid.uuid4()}.mp4"
        out_path.write_bytes(video_resp.content)
        return out_path
    except Exception as e:
        logger.warning(f"Grok video API not available or failed: {e}")
        return None

# === Celery Task ===
@celery.task(bind=True, max_retries=3)
def process_grok_clip_task(self, prompt: str, caption: str, user_id: str, audio_file: Optional[str] = None, base_video_file: Optional[str] = None):
    task_id = self.request.id
    self.update_state(state='PROGRESS', meta={'progress': 10, 'status': 'Starting generation'})

    base_video_path = None

    # Try future text-to-video API
    base_video_path = generate_grok_video(prompt)

    # Fallback to user-uploaded base
    if not base_video_path and base_video_file:
        base_video_path = UPLOAD_FOLDER / base_video_file
        if not base_video_path.exists():
            raise ValueError("Uploaded base video not found")

    if not base_video_path:
        raise ValueError("No base video generated or provided. Generate in Grok app/web and upload.")

    self.update_state(state='PROGRESS', meta={'progress': 30, 'status': 'Loading video'})

    try:
        clip = VideoFileClip(str(base_video_path))
        duration = clip.duration
        title = prompt[:50] + "..." if len(prompt) > 50 else prompt
        clip.close()
    except Exception as e:
        raise ValueError(f"Invalid base video: {str(e)}")

    filename = secure_filename(f"{uuid.uuid4()}.mp4")
    output_path = UPLOAD_FOLDER / filename

    self.update_state(state='PROGRESS', meta={'progress': 50, 'status': 'Processing audio'})

    if audio_file:
        user_audio_path = UPLOAD_FOLDER / audio_file
        if user_audio_path.exists():
            user_audio = process_user_audio(user_audio_path, duration)
        else:
            raise ValueError("Uploaded audio file not found")
    else:
        user_audio = VideoFileClip(str(base_video_path)).audio

    self.update_state(state='PROGRESS', meta={'progress': 70, 'status': 'Enhancing video'})

    enhance_video(base_video_path, output_path, title, caption, user_audio)

    self.update_state(state='PROGRESS', meta={'progress': 85, 'status': 'Analyzing with Grok 4'})

    keyframes = extract_keyframes(output_path, n=6)
    analysis = Grok4API.analyze_clip(keyframes, caption)

    # Cleanup keyframes
    for kf in keyframes:
        try: kf.unlink(missing_ok=True)
        except: pass

    video_url = url_for('static', filename=filename, _external=True)

    return {
        "video_url": video_url,
        "analysis": analysis,
        "caption": caption,
        "prompt": prompt,
        "user_id": user_id,
        "progress": 100,
        "status": "completed"
    }

# === Routes ===
@app.route('/clip_grok', methods=['POST'])
@limiter.limit("10 per minute")
def clip_grok():
    data = request.json or {}
    prompt = data.get('prompt', 'A vibrant cinematic abstract music visualization with pulsing lights and particles')
    caption = data.get('caption', 'AI-generated music magic ✨')
    user_id = data.get('user_id', 'anonymous')
    audio_filename = data.get('audio_filename')
    base_video_filename = data.get('base_video_filename')

    task = process_grok_clip_task.delay(prompt, caption, user_id, audio_filename, base_video_filename)

    prompt_tips = (
        "Pro tip for best Grok Imagine results: Describe mood, tempo, camera moves, lighting. "
        "E.g., 'Cyberpunk neon city flythrough with pulsing bass, dramatic parallax zoom, vertical 9:16'"
    )

    return jsonify({
        "task_id": task.id,
        "note": "Text-to-video API not public yet. Generate in Grok app/web, download, and upload via /upload_base.",
        "prompt_tips": prompt_tips
    })

@app.route('/upload_audio', methods=['POST'])
def upload_audio():
    if 'audio' not in request.files:
        return jsonify({"error": "No audio file"}), 400
    file = request.files['audio']
    if file.filename == '':
        return jsonify({"error": "No selected file"}), 400
    filename = secure_filename(f"user_audio_{uuid.uuid4()}_{file.filename}")
    file.save(UPLOAD_FOLDER / filename)
    return jsonify({"audio_filename": filename})

@app.route('/upload_base', methods=['POST'])
def upload_base():
    if 'base_video' not in request.files:
        return jsonify({"error": "No base video file"}), 400
    file = request.files['base_video']
    if file.filename == '':
        return jsonify({"error": "No selected file"}), 400
    filename = secure_filename(f"base_{uuid.uuid4()}_{file.filename}")
    file.save(UPLOAD_FOLDER / filename)
    return jsonify({"base_video_filename": filename})

@app.route('/task_status/<task_id>')
def task_status(task_id):
    task = process_grok_clip_task.AsyncResult(task_id)
    if task.state == 'PENDING':
        response = {'state': task.state, 'status': 'Pending...'}
    elif task.state in ['PROGRESS', 'SUCCESS']:
        response = {'state': task.state, 'result': task.info if task.info else {}}
    else:
        response = {'state': task.state, 'status': str(task.info) if task.info else 'Failed'}
    return jsonify(response)

@app.route('/')
def index():
    return "MusicVines Pro V2.2 (Grok Imagine Edition) API Running – Fully Legal & AI-Powered!"

if __name__ == '__main__':
    os.makedirs(UPLOAD_FOLDER, exist_ok=True)
    app.run(debug=False, host='0.0.0.0', port=5000)